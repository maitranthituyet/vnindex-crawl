name: Scrape VNIndex Data

on:
  schedule:
    - cron: "10 08 * * 1-5"  # Runs at 08:10 UTC (which is 15:10 Vietnam Time, GMT+7) "49 18 * * 1-5" 
  workflow_dispatch:  # Allows manual runs

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas gspread oauth2client selenium

      - name: Install Chrome & Chromedriver
        run: |
          sudo apt-get update
          sudo apt-get install -y wget unzip
          sudo apt-get install -y chromium-browser chromium-chromedriver
          echo "CHROMEDRIVER_PATH=$(which chromedriver)" >> $GITHUB_ENV
          echo "CHROME_PATH=$(which chromium-browser)" >> $GITHUB_ENV

      - name: Run Scraper
        env:
          GOOGLE_SHEETS_CREDENTIALS: ${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}
          CHROMEDRIVER_PATH: ${{ env.CHROMEDRIVER_PATH }}
          CHROME_PATH: ${{ env.CHROME_PATH }}
        run: python vnindex_crawl.py
